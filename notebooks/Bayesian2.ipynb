{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gibbs.dataclass import GibbsResult, get_results\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from gibbs.learning.bayesian_learning import BayesianLearning\n",
    "from gibbs.learning.constraint_matrix import ConstraintMatrixFactory, DumbConstraintMatrixFactory\n",
    "from qiskit.quantum_info import Statevector\n",
    "from gibbs.learning.klocal_pauli_basis import KLocalPauliBasis\n",
    "from scipy.linalg import block_diag\n",
    "from scipy.sparse import bmat\n",
    "from qiskit.quantum_info import state_fidelity\n",
    "from gibbs.utils import number_of_elements, simple_purify_hamiltonian, spectral_dec,printarray\n",
    "import plotly_express as px\n",
    "# plt.rcParams['text.usetex'] = True\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "gibbsresults = get_results(\"../saved_simulations/turbo/random1localheisenberg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will need to sample 255 Paulis for each one of the states. In total,5.4E+09\n"
     ]
    }
   ],
   "source": [
    "n=4\n",
    "k=2\n",
    "nfields = 20\n",
    "shots = 1e6\n",
    "prep_noise = 1e-1\n",
    "basisH = KLocalPauliBasis(k,n,False)\n",
    "cmat = ConstraintMatrixFactory(n,k,k+1)\n",
    "c_original = np.zeros(basisH.size)\n",
    "c_original[basisH.pauli_to_num(\"XX\"+\"I\"*(n-2)):basisH.pauli_to_num(\"I\"*(n-2)+\"XX\")+1]=1\n",
    "c_original_prior = c_original.copy()\n",
    "# c_original[basisH.pauli_to_num(\"XX\"+\"I\"*(n-2)):] += np.random.normal(0,prep_noise,size=c_original[basisH.pauli_to_num(\"XX\"+\"I\"*(n-2)):].size)\n",
    "c_original += np.random.normal(0,prep_noise,size=c_original.size)\n",
    "\n",
    "print(f\"We will need to sample {KLocalPauliBasis(2*k,n,False).size} Paulis for each one of the states. In total,{int((nfields+1)*shots*KLocalPauliBasis(2*k,n,False).size):.1E}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestep =-1\n",
    "states = [g.state_ansatz(timestep) for g in gibbsresults]\n",
    "control_fields = [g.coriginal-gibbsresults[0].coriginal for g in gibbsresults]\n",
    "initial_arguments = {\n",
    "    \"states\":states,\n",
    "    \"control_fields\": control_fields,\n",
    "    \"cmat_factory\": ConstraintMatrixFactory(num_qubits:=gibbsresults[0].num_qubits,3,3),\n",
    "    \"prior_mean\": c_original_prior,\n",
    "    \"prior_covariance\": (prep_noise,1e-3),\n",
    "    \"sampling_std\": 1/np.sqrt(shots),\n",
    "    \"shots\": shots\n",
    "    }\n",
    "bl = BayesianLearning(**initial_arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In total we are performing 0.000e+00 shots\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (39,) (63,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m s,v \u001b[39m=\u001b[39m spectral_dec(A_regular)\n\u001b[1;32m      5\u001b[0m candidate \u001b[39m=\u001b[39m v[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mcopy(); candidate \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39mnorm(candidate)\n\u001b[0;32m----> 6\u001b[0m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39mnorm(c_original\u001b[39m/\u001b[39;49mnp\u001b[39m.\u001b[39;49mlinalg\u001b[39m.\u001b[39;49mnorm(c_original) \u001b[39m+\u001b[39;49m candidate) \u001b[39m<\u001b[39m np\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39mnorm(c_original\u001b[39m/\u001b[39mnp\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39mnorm(c_original) \u001b[39m-\u001b[39m candidate):\n\u001b[1;32m      7\u001b[0m     candidate \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mcandidate\n\u001b[1;32m      8\u001b[0m fig,ax \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplots(\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m,figsize\u001b[39m=\u001b[39m(\u001b[39m10\u001b[39m,\u001b[39m5\u001b[39m))\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (39,) (63,) "
     ]
    }
   ],
   "source": [
    "regular_cmat_factory=ConstraintMatrixFactory(num_qubits,2,3)\n",
    "A_regular = regular_cmat_factory.create_cmat(states[0],shots)\n",
    "print(f\"In total we are performing {(regular_shots:=regular_cmat_factory.counter_shots):.3e} shots\")\n",
    "s,v = spectral_dec(A_regular)\n",
    "candidate = v[-1].copy(); candidate /= np.linalg.norm(candidate)\n",
    "if np.linalg.norm(c_original/np.linalg.norm(c_original) + candidate) < np.linalg.norm(c_original/np.linalg.norm(c_original) - candidate):\n",
    "    candidate = -candidate\n",
    "fig,ax = plt.subplots(1,2,figsize=(10,5))\n",
    "ax[0].stairs(c_original/np.linalg.norm(c_original),lw=3)\n",
    "ax[0].stairs(candidate)\n",
    "ax[1].plot(np.log(s),marker=\".\")\n",
    "print(f\"We start with a hamiltonian error of:{np.linalg.norm(c_original_prior-c_original)} and end up with {np.linalg.norm(candidate*np.linalg.norm(c_original)-c_original)} \")\n",
    "print(f\"The prior fidelity is: {state_fidelity(simple_purify_hamiltonian(basisH.vector_to_pauli_op(c_original_prior)),simple_purify_hamiltonian(basisH.vector_to_pauli_op(c_original)))} and the posterior fidelity is: {state_fidelity(simple_purify_hamiltonian(basisH.vector_to_pauli_op(candidate*np.linalg.norm(c_original))),simple_purify_hamiltonian(basisH.vector_to_pauli_op(c_original)))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dumb_cmat_factory=DumbConstraintMatrixFactory(num_qubits,2,3)\n",
    "A_dumb = dumb_cmat_factory.create_cmat(states[0],shots//6.894)\n",
    "print(f\"In total we are performing {(dumb_shots:=dumb_cmat_factory.counter_shots):.3e} shots\")\n",
    "print(f\"That is {dumb_shots/regular_shots:.3e} more times than we needed.\")\n",
    "s,v = spectral_dec(A_dumb)\n",
    "candidate = v[-1].copy(); candidate /= np.linalg.norm(candidate)\n",
    "if np.linalg.norm(c_original/np.linalg.norm(c_original) + candidate) < np.linalg.norm(c_original/np.linalg.norm(c_original) - candidate):\n",
    "    candidate = -candidate\n",
    "fig,ax = plt.subplots(1,2,figsize=(10,5))\n",
    "ax[0].stairs(c_original/np.linalg.norm(c_original),lw=3)\n",
    "ax[0].stairs(candidate)\n",
    "ax[1].plot(np.log(s),marker=\".\")\n",
    "print(f\"We start with a hamiltonian error of:{np.linalg.norm(c_original_prior-c_original)} and end up with {np.linalg.norm(candidate*np.linalg.norm(c_original)-c_original)} \")\n",
    "print(f\"The prior fidelity is: {state_fidelity(simple_purify_hamiltonian(basisH.vector_to_pauli_op(c_original_prior)),simple_purify_hamiltonian(basisH.vector_to_pauli_op(c_original)))} and the posterior fidelity is: {state_fidelity(simple_purify_hamiltonian(basisH.vector_to_pauli_op(candidate*np.linalg.norm(c_original))),simple_purify_hamiltonian(basisH.vector_to_pauli_op(c_original)))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m A \u001b[39m=\u001b[39m bl\u001b[39m.\u001b[39;49mblock_control_matrix(\u001b[39mrange\u001b[39;49m(\u001b[39m5\u001b[39;49m))\n\u001b[1;32m      2\u001b[0m s,v \u001b[39m=\u001b[39m spectral_dec(A)\n\u001b[1;32m      3\u001b[0m candidate \u001b[39m=\u001b[39m v[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][:c_original\u001b[39m.\u001b[39msize]\u001b[39m.\u001b[39mcopy(); candidate \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39mnorm(candidate)\n",
      "File \u001b[0;32m~/GH/Julien/gibbs_code/gibbs/learning/bayesian_learning.py:164\u001b[0m, in \u001b[0;36mBayesianLearning.block_control_matrix\u001b[0;34m(self, indexes)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mblock_control_matrix\u001b[39m(\u001b[39mself\u001b[39m, indexes\u001b[39m=\u001b[39m\u001b[39mlist\u001b[39m[\u001b[39mint\u001b[39m]):\n\u001b[0;32m--> 164\u001b[0m     constraint_matrices \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconstraint_matrix(i) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m indexes]\n\u001b[1;32m    165\u001b[0m     \u001b[39mreturn\u001b[39;00m bmat(\n\u001b[1;32m    166\u001b[0m         [[constraint_matrices[\u001b[39m0\u001b[39m]] \u001b[39m+\u001b[39m [\u001b[39mNone\u001b[39;00m] \u001b[39m*\u001b[39m (\u001b[39mlen\u001b[39m(constraint_matrices) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)]\n\u001b[1;32m    167\u001b[0m         \u001b[39m+\u001b[39m [\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    170\u001b[0m         ]\n\u001b[1;32m    171\u001b[0m     )\n",
      "File \u001b[0;32m~/GH/Julien/gibbs_code/gibbs/learning/bayesian_learning.py:164\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mblock_control_matrix\u001b[39m(\u001b[39mself\u001b[39m, indexes\u001b[39m=\u001b[39m\u001b[39mlist\u001b[39m[\u001b[39mint\u001b[39m]):\n\u001b[0;32m--> 164\u001b[0m     constraint_matrices \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconstraint_matrix(i) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m indexes]\n\u001b[1;32m    165\u001b[0m     \u001b[39mreturn\u001b[39;00m bmat(\n\u001b[1;32m    166\u001b[0m         [[constraint_matrices[\u001b[39m0\u001b[39m]] \u001b[39m+\u001b[39m [\u001b[39mNone\u001b[39;00m] \u001b[39m*\u001b[39m (\u001b[39mlen\u001b[39m(constraint_matrices) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)]\n\u001b[1;32m    167\u001b[0m         \u001b[39m+\u001b[39m [\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    170\u001b[0m         ]\n\u001b[1;32m    171\u001b[0m     )\n",
      "File \u001b[0;32m~/GH/Julien/gibbs_code/gibbs/learning/bayesian_learning.py:53\u001b[0m, in \u001b[0;36mBayesianLearning.constraint_matrix\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconstraint_matrix\u001b[39m(\u001b[39mself\u001b[39m, index: \u001b[39mint\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[1;32m     52\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcmats[index] \u001b[39m==\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 53\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcmats[index] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcmat_factory\u001b[39m.\u001b[39;49mcreate_cmat(\n\u001b[1;32m     54\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstates[index], shots\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshots\n\u001b[1;32m     55\u001b[0m         )\n\u001b[1;32m     57\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcmats[index]\n",
      "File \u001b[0;32m~/GH/Julien/gibbs_code/gibbs/learning/constraint_matrix.py:106\u001b[0m, in \u001b[0;36mConstraintMatrixFactory.create_cmat\u001b[0;34m(self, state, shots)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_cmat\u001b[39m(\n\u001b[1;32m     97\u001b[0m     \u001b[39mself\u001b[39m, state: QuantumCircuit \u001b[39m|\u001b[39m Statevector, shots: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m10000\u001b[39m\n\u001b[1;32m     98\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[1;32m     99\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Creates a constraint matrix from the sampled paulis.\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \n\u001b[1;32m    101\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[39m        Sm_basis: A list of k paulis for the m coordinate.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 106\u001b[0m     sampled_paulis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msample_paulis(state, shots)\n\u001b[1;32m    107\u001b[0m     data \u001b[39m=\u001b[39m []\n\u001b[1;32m    108\u001b[0m     row \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/GH/Julien/gibbs_code/gibbs/learning/constraint_matrix.py:71\u001b[0m, in \u001b[0;36mConstraintMatrixFactory.sample_paulis\u001b[0;34m(self, state, shots)\u001b[0m\n\u001b[1;32m     66\u001b[0m     estimator \u001b[39m=\u001b[39m Estimator()\n\u001b[1;32m     67\u001b[0m     observables \u001b[39m=\u001b[39m [\n\u001b[1;32m     68\u001b[0m         Pauli(pauli \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mI\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m*\u001b[39m \u001b[39mlen\u001b[39m(pauli))\n\u001b[1;32m     69\u001b[0m         \u001b[39mfor\u001b[39;00m pauli \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msampling_basis\u001b[39m.\u001b[39mpaulis_list\n\u001b[1;32m     70\u001b[0m     ]\n\u001b[0;32m---> 71\u001b[0m     result \u001b[39m=\u001b[39m estimator\u001b[39m.\u001b[39;49mrun(\n\u001b[1;32m     72\u001b[0m         [state] \u001b[39m*\u001b[39;49m \u001b[39mlen\u001b[39;49m(observables),\n\u001b[1;32m     73\u001b[0m         observables\u001b[39m=\u001b[39;49mobservables,\n\u001b[1;32m     74\u001b[0m         shots\u001b[39m=\u001b[39;49mshots,\n\u001b[1;32m     75\u001b[0m     )\u001b[39m.\u001b[39mresult()\n\u001b[1;32m     76\u001b[0m     \u001b[39mreturn\u001b[39;00m result\u001b[39m.\u001b[39mvalues\n\u001b[1;32m     77\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(state, (Statevector, DensityMatrix)):\n",
      "File \u001b[0;32m~/python_environements/test_easy_instalation/lib64/python3.10/site-packages/qiskit/primitives/base/base_estimator.py:235\u001b[0m, in \u001b[0;36mBaseEstimator.run\u001b[0;34m(self, circuits, observables, parameter_values, **run_options)\u001b[0m\n\u001b[1;32m    232\u001b[0m run_opts \u001b[39m=\u001b[39m copy(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions)\n\u001b[1;32m    233\u001b[0m run_opts\u001b[39m.\u001b[39mupdate_options(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mrun_options)\n\u001b[0;32m--> 235\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(\n\u001b[1;32m    236\u001b[0m     circuits,\n\u001b[1;32m    237\u001b[0m     observables,\n\u001b[1;32m    238\u001b[0m     parameter_values,\n\u001b[1;32m    239\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mrun_opts\u001b[39m.\u001b[39;49m\u001b[39m__dict__\u001b[39;49m,\n\u001b[1;32m    240\u001b[0m )\n",
      "File \u001b[0;32m~/python_environements/test_easy_instalation/lib64/python3.10/site-packages/qiskit/primitives/estimator.py:186\u001b[0m, in \u001b[0;36mEstimator._run\u001b[0;34m(self, circuits, observables, parameter_values, **run_options)\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_observables\u001b[39m.\u001b[39mappend(observable)\n\u001b[1;32m    183\u001b[0m job \u001b[39m=\u001b[39m PrimitiveJob(\n\u001b[1;32m    184\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call, circuit_indices, observable_indices, parameter_values, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mrun_options\n\u001b[1;32m    185\u001b[0m )\n\u001b[0;32m--> 186\u001b[0m job\u001b[39m.\u001b[39;49msubmit()\n\u001b[1;32m    187\u001b[0m \u001b[39mreturn\u001b[39;00m job\n",
      "File \u001b[0;32m~/python_environements/test_easy_instalation/lib64/python3.10/site-packages/qiskit/primitives/primitive_job.py:43\u001b[0m, in \u001b[0;36mPrimitiveJob.submit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_future \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     41\u001b[0m     \u001b[39mraise\u001b[39;00m JobError(\u001b[39m\"\u001b[39m\u001b[39mPrimitive job has already been submitted.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 43\u001b[0m \u001b[39mwith\u001b[39;00m ThreadPoolExecutor(max_workers\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m) \u001b[39mas\u001b[39;00m executor:\n\u001b[1;32m     44\u001b[0m     future \u001b[39m=\u001b[39m executor\u001b[39m.\u001b[39msubmit(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function, \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_kwargs)\n\u001b[1;32m     45\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_future \u001b[39m=\u001b[39m future\n",
      "File \u001b[0;32m/usr/lib64/python3.10/concurrent/futures/_base.py:649\u001b[0m, in \u001b[0;36mExecutor.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    648\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__exit__\u001b[39m(\u001b[39mself\u001b[39m, exc_type, exc_val, exc_tb):\n\u001b[0;32m--> 649\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshutdown(wait\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    650\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib64/python3.10/concurrent/futures/thread.py:235\u001b[0m, in \u001b[0;36mThreadPoolExecutor.shutdown\u001b[0;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[39mif\u001b[39;00m wait:\n\u001b[1;32m    234\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_threads:\n\u001b[0;32m--> 235\u001b[0m         t\u001b[39m.\u001b[39;49mjoin()\n",
      "File \u001b[0;32m/usr/lib64/python3.10/threading.py:1096\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1093\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mcannot join current thread\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1095\u001b[0m \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1096\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_wait_for_tstate_lock()\n\u001b[1;32m   1097\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1098\u001b[0m     \u001b[39m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m     \u001b[39m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[39m=\u001b[39m\u001b[39mmax\u001b[39m(timeout, \u001b[39m0\u001b[39m))\n",
      "File \u001b[0;32m/usr/lib64/python3.10/threading.py:1116\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1113\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1116\u001b[0m     \u001b[39mif\u001b[39;00m lock\u001b[39m.\u001b[39;49macquire(block, timeout):\n\u001b[1;32m   1117\u001b[0m         lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m   1118\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "A = bl.block_control_matrix(range(5))\n",
    "s,v = spectral_dec(A)\n",
    "candidate = v[-1][:c_original.size].copy(); candidate /= np.linalg.norm(candidate)\n",
    "if np.linalg.norm(c_original/np.linalg.norm(c_original) + candidate) < np.linalg.norm(c_original/np.linalg.norm(c_original) - candidate):\n",
    "    candidate = -candidate  \n",
    "fig,ax = plt.subplots(1,2,figsize=(10,5))\n",
    "ax[0].stairs(c_original/np.linalg.norm(c_original),lw=3)\n",
    "ax[0].stairs(candidate)\n",
    "ax[1].plot(np.log(s),marker=\".\")\n",
    "print(f\"We start with a hamiltonian error of:{np.linalg.norm(c_original_prior-c_original)} and end up with {np.linalg.norm(candidate*np.linalg.norm(c_original)-c_original)} \")\n",
    "print(f\"The prior fidelity is: {state_fidelity(simple_purify_hamiltonian(basisH.vector_to_pauli_op(c_original_prior)),simple_purify_hamiltonian(basisH.vector_to_pauli_op(c_original)))} and the posterior fidelity is: {state_fidelity(simple_purify_hamiltonian(basisH.vector_to_pauli_op(candidate*np.linalg.norm(c_original))),simple_purify_hamiltonian(basisH.vector_to_pauli_op(c_original)))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 (828, 828) (660,) (39,)\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Size of x0: 660 and constraint matrix: (828, 828) don't match",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m covs \u001b[39m=\u001b[39m [bl\u001b[39m.\u001b[39mtotal_cov]\n\u001b[1;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m indexes \u001b[39min\u001b[39;00m ([(\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m,\u001b[39m3\u001b[39m),(\u001b[39m0\u001b[39m,\u001b[39m4\u001b[39m,\u001b[39m5\u001b[39m,\u001b[39m6\u001b[39m),(\u001b[39m0\u001b[39m,\u001b[39m7\u001b[39m,\u001b[39m8\u001b[39m,\u001b[39m9\u001b[39m),(\u001b[39m0\u001b[39m,\u001b[39m10\u001b[39m,\u001b[39m11\u001b[39m,\u001b[39m12\u001b[39m),(\u001b[39m0\u001b[39m,\u001b[39m13\u001b[39m,\u001b[39m14\u001b[39m,\u001b[39m15\u001b[39m)]):\n\u001b[0;32m----> 4\u001b[0m     posterior_mean \u001b[39m=\u001b[39m bl\u001b[39m.\u001b[39;49mupdate_mean(indexes,options\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mmaxiter\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m100\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mxrtol\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m1e-3\u001b[39;49m  , \u001b[39m\"\u001b[39;49m\u001b[39mdisp\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39mTrue\u001b[39;49;00m})\n\u001b[1;32m      5\u001b[0m     posterior_cov \u001b[39m=\u001b[39m bl\u001b[39m.\u001b[39mupdate_cov(posterior_mean,indexes)\n\u001b[1;32m      6\u001b[0m     means\u001b[39m.\u001b[39mappend(bl\u001b[39m.\u001b[39mcurrent_mean)\n",
      "File \u001b[0;32m~/GH/Julien/gibbs_code/gibbs/learning/bayesian_learning.py:199\u001b[0m, in \u001b[0;36mBayesianLearning.update_mean\u001b[0;34m(self, indexes, options)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mupdate_mean\u001b[39m(\n\u001b[1;32m    195\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    196\u001b[0m     indexes: \u001b[39mlist\u001b[39m[\u001b[39mint\u001b[39m],\n\u001b[1;32m    197\u001b[0m     options: \u001b[39mdict\u001b[39m \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mmaxiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m1e5\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mxrtol\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m1e-3\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mdisp\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mTrue\u001b[39;00m},\n\u001b[1;32m    198\u001b[0m ):\n\u001b[0;32m--> 199\u001b[0m     min_prob \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mminimization_problem(indexes)\n\u001b[1;32m    200\u001b[0m     posterior_mean \u001b[39m=\u001b[39m minimize(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmin_prob, options\u001b[39m=\u001b[39moptions)\u001b[39m.\u001b[39mx\n\u001b[1;32m    201\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    202\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe cost function ends up with a value of:\u001b[39m\u001b[39m{\u001b[39;00mmin_prob[\u001b[39m'\u001b[39m\u001b[39mfun\u001b[39m\u001b[39m'\u001b[39m](posterior_mean)\u001b[39m \u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, it started with a value of \u001b[39m\u001b[39m{\u001b[39;00mmin_prob[\u001b[39m'\u001b[39m\u001b[39mfun\u001b[39m\u001b[39m'\u001b[39m](min_prob[\u001b[39m'\u001b[39m\u001b[39mx0\u001b[39m\u001b[39m'\u001b[39m])\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    203\u001b[0m     )\n",
      "File \u001b[0;32m~/GH/Julien/gibbs_code/gibbs/learning/bayesian_learning.py:186\u001b[0m, in \u001b[0;36mBayesianLearning.minimization_problem\u001b[0;34m(self, indexes)\u001b[0m\n\u001b[1;32m    181\u001b[0m x0 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate(\n\u001b[1;32m    182\u001b[0m     [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_mean, \u001b[39m*\u001b[39m[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol_fields[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m indexes[\u001b[39m1\u001b[39m:]]]\n\u001b[1;32m    183\u001b[0m )\n\u001b[1;32m    184\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(indexes), A\u001b[39m.\u001b[39mshape, x0\u001b[39m.\u001b[39mshape, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_mean\u001b[39m.\u001b[39mshape)\n\u001b[1;32m    185\u001b[0m \u001b[39massert\u001b[39;00m (\n\u001b[0;32m--> 186\u001b[0m     x0\u001b[39m.\u001b[39msize \u001b[39m==\u001b[39m A\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[1;32m    187\u001b[0m ), \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSize of x0: \u001b[39m\u001b[39m{\u001b[39;00mx0\u001b[39m.\u001b[39msize\u001b[39m}\u001b[39;00m\u001b[39m and constraint matrix: \u001b[39m\u001b[39m{\u001b[39;00mA\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m don\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt match\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    189\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcallback\u001b[39m(xx):\n\u001b[1;32m    190\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cost_function(xx, A, indexes)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Size of x0: 660 and constraint matrix: (828, 828) don't match"
     ]
    }
   ],
   "source": [
    "means = [bl.current_mean]\n",
    "covs = [bl.total_cov]\n",
    "for indexes in ([(0,1,2,3),(0,4,5,6),(0,7,8,9),(0,10,11,12),(0,13,14,15)]):\n",
    "    posterior_mean = bl.update_mean(indexes,options={\"maxiter\": 100, \"xrtol\": 1e-3  , \"disp\": True})\n",
    "    posterior_cov = bl.update_cov(posterior_mean,indexes)\n",
    "    means.append(bl.current_mean)\n",
    "    covs.append(bl.total_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.imshow(covs[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,2,figsize=(15,5))\n",
    "ax[0].stairs(c_original,label=\"preparation\")\n",
    "ax[0].stairs(c_original_prior,label = \"prior\")\n",
    "ax[0].stairs(posterior_mean[:c_original.size],label=\"posterior\")\n",
    "ax[0].legend()\n",
    "width = 0.9\n",
    "ax[1].bar(np.arange(bl.size),np.abs(c_original-c_original_prior),width,label=\"prior error\",lw=2,fill=True)\n",
    "ax[1].bar(np.arange(bl.size),np.abs(c_original-posterior_mean[:c_original.size]),0.6*width,label=\"posterior error\",fill=True)\n",
    "ax[1].stairs(posterior_cov.diagonal()[:c_original.size],np.arange(bl.size+1)-1/2,label=\"std\",color=\"red\")\n",
    "ax[1].legend()\n",
    "# ax[2].stairs(posterior_mean,label=\"posterior\")\n",
    "# ax[2].stairs(x_ideal,label=\"ideal\")\n",
    "# ax[2].stairs(posterior_cov.diagonal(),label=\"posterior std\")\n",
    "# ax[2].legend()\n",
    "print(f\"We start with a hamiltonian error of:{np.linalg.norm(c_original_prior-c_original)} and end up with {np.linalg.norm(posterior_mean[:c_original.size]-c_original)} \")\n",
    "print(f\"The prior fidelity is: {state_fidelity(simple_purify_hamiltonian(basisH.vector_to_pauli_op(c_original_prior)),simple_purify_hamiltonian(basisH.vector_to_pauli_op(c_original)))} and the posterior fidelity is: {state_fidelity(simple_purify_hamiltonian(basisH.vector_to_pauli_op(posterior_mean[:c_original.size])),simple_purify_hamiltonian(basisH.vector_to_pauli_op(c_original)))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_easy_instalation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a99669db2c788b5eb6a3f1de1af58ba979ab8e9c6ee57e40d99f496c2ca91e4c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
